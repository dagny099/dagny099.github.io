---
title: "Publications"
permalink: /publications/
header:
  opacity: "0.9"
  overlay_image: "/assets/images/babybees_01.jpg"
---

## Overview of Research

When performing natural tasks in real world contexts, people move their eye gaze several times per second, for example when scanning a webpage for a desired link, looking for a familiar face in the crowd, or checking a crosswalk for pedestrians.  

**Where** the eyes are looking and **how long** they linger in a particular spot are naturally occurring behaviors that can indicate which scene regions are visually or cognitively **salient**.  

•	My broad area of interest is to understand how people combine bottom-up visual information and top-down scene knowledge to selectively deploy the eyes during natural tasks, e.g. visual search, learning & memory.

•	Specifically, how does context-specific learning (e.g. the familiar layout of one’s bedroom or TV remote control) influence spatial and temporal characteristics of attentional processing.  

•	Modeling individual differences in search behavior and using those models to enhance visual exploration of familiar contexts - Can computational models learn person-specific eye movement parameters and predict what regions of a scene or visual display will attract a person’s attention?

## Publications

Hidalgo-Sotelo, B. & Oliva, A. (2010).  Person, place, and past influence eye movements during visual search.  In S. Ohlsson & R. Catrambone (Eds.), Proceedings of the 32nd Annual Conference of the Cognitive Science Society, (pp. 820-825). Austin, TX: Cognitive Science Society.

Ehinger, K.*, Hidalgo-Sotelo, B. *, Torralba, A. & Oliva, A. (2009).  Modeling Search for People in 900 Scenes: A combined source model of eye guidance. Visual Cognition, 17(6): 945-978. 

Rich, A., Kunar M., VanWert M., Hidalgo-Sotelo B., Horowitz T., & Wolfe J. (2008).  Why do we miss rare targets? Exploring the boundaries of the low prevalence effect. Journal of Vision, 8(15):15, 1-17.

Hidalgo-Sotelo B., Oliva A.,& Torralba A. (2005).  Human Learning of Contextual Priors for Object Search: Where does the time go?  Proceedings of the 3rd Workshop on Attention and Performance at CVPR. Washington, DC: IEEE Computer Society.

## Posters

Hidalgo-Sotelo, B., & Oliva, A. (August 2010). Person, place, and past influence eye movments during visual search. Cognitive Science Society Annual Meeting, Portland OR. 

Hidalgo-Sotelo, B., & Oliva, A. (May 2010). History repeats itself: A role for observer-dependent scene context in search. Vision Sciences Society Annual Meeting, Naples FL.

Hidalgo-Sotelo, B., & Oliva, A. (May 2008). Delaying initial saccade latency in familiar scenes improves search guidance. Tufts Conference on Cognitive Neuroscience of Visual Knowledge: Where vision meets memory. Boston MA. 

Hidalgo-Sotelo, B., & Oliva, A. (May 2008). Look before you leap: Lengthening initial saccade latency in familiar scenes improves search guidance. Vision Sciences Society Annual Meeting, Naples FL.

Rich, A., Kunar, M., Van Wert, M., Hidalgo-Sotelo, B., & Wolfe, J. (May 2007).  Do rare features pop out? Exploring the boundaries of the low prevalence effect. Vision Sciences Society Annual Meeting, Sarasota FL.
Hidalgo-Sotelo, B., & Oliva, A. (May 2006). Decomposing the effect of contextual priors in search: Where does the time go? Vision Sciences Society Annual Meeting, Sarasota FL.

Rich, A. N., Hidalgo-Sotelo, B., Kunar, M. A., Van Wert, M. J., & Wolfe, J. M. (May 2006). 
What happens during search for rare targets? Eye movements in low prevalence visual search. Vision Sciences Society Annual Meeting, Sarasota FL.

Kenner N., Hidalgo-Sotelo B., & Oliva A .(May 2005).  Rapid Goal-Directed Exploration of a Scene: The Interaction of Contextual Guidance and Salience. Vision Sciences Society Annual Meeting, Sarasota FL.

